{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19302404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf42e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce9eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8163f4a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "letters = set()\n",
    "for i in df['text']:\n",
    "    for j in i:\n",
    "        letters.add(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646edb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ''\n",
    "for i in df['text']:\n",
    "    all_text += i.lower()\n",
    "counter = pd.Series(Counter(all_text)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fef1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "alp='абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "counter_rus = counter[counter.index.to_series().isin(list(alp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdfdfac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = counter[counter > CUTOFF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6582ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_list = counter.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58afed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizator:\n",
    "    def __init__(self, tokens: list, max_length: int):\n",
    "        self.num_tokens = len(tokens)\n",
    "        self.tokens = tokens\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def tokenize(self, text: str) -> torch.Tensor:\n",
    "        res_text = []\n",
    "        \n",
    "        if len(text) > self.max_length:\n",
    "            text = text[:self.max_length]\n",
    "        \n",
    "        for i in text:\n",
    "            if i not in self.tokens:\n",
    "                continue\n",
    "            res_letter = [0]*self.num_tokens\n",
    "            res_letter[self.tokens.index(i)] = 1\n",
    "            res_text.append(res_letter)\n",
    "            \n",
    "        difference = self.max_length - len(res_text)\n",
    "        for i in range(difference):\n",
    "            res_text.append([0]*self.num_tokens)\n",
    "            \n",
    "        return torch.Tensor(res_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2a77518",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizator = Tokenizator(counter_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8121a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f65552ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized = df_tokenized.drop(['forwarded_from'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32f6c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized['tokenized_text'] = df_tokenized['text'].apply(tokenizator.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eed66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "slovarb = {v: k for k,v in enumerate(df_tokenized['from'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50bdb70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized['tokenized_sender'] = df_tokenized['from'].apply(lambda x: torch.tensor(slovarb[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a11e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized.to_pickle('data/tokenized_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fc99c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle('data/tokenized_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
